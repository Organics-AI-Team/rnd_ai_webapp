/**
 * Test Gemini 2.5 Flash Streaming API
 * Debug script to test streaming responses directly
 */

require('dotenv').config({ path: '.env.local' });
const { GoogleGenerativeAI } = require('@google/generative-ai');

async function testGeminiStreaming() {
  try {
    console.log('ü§ñ Testing Gemini 2.5 Flash Streaming API...');

    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY not found');
    }

    const genAI = new GoogleGenerativeAI(apiKey);
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    console.log('‚úÖ Model initialized');

    // Test 1: Simple generation without streaming
    console.log('\nüìù Testing simple generation...');
    const simplePrompt = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∏‡πà‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏ß‡πÅ‡∏´‡πâ‡∏á 1-2 ‡∏ä‡∏ô‡∏¥‡∏î";

    const simpleResult = await model.generateContent(simplePrompt);
    const simpleResponse = await simpleResult.response;
    const simpleText = simpleResponse.text();

    console.log('‚úÖ Simple generation works!');
    console.log('üìÑ Response:', simpleText.substring(0, 200) + '...');

    // Test 2: Chat without streaming
    console.log('\nüí¨ Testing chat without streaming...');
    const chat = model.startChat({
      history: [],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 500,
      }
    });

    const chatResult = await chat.sendMessage("‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÉ‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∏‡πà‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?");
    const chatResponse = await chatResult.response;
    const chatText = chatResponse.text();

    console.log('‚úÖ Chat without streaming works!');
    console.log('üìÑ Response:', chatText.substring(0, 200) + '...');

    // Test 3: Streaming (the problematic one)
    console.log('\nüåä Testing streaming...');
    const streamChat = model.startChat({
      history: [],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 500,
      }
    });

    console.log('üîÆ Sending streaming request...');
    const streamResult = await streamChat.sendMessageStream("‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÉ‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∏‡πà‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?");

    let chunkCount = 0;
    let totalText = '';

    for await (const chunk of streamResult.stream) {
      const text = chunk.text();
      chunkCount++;
      totalText += text;

      if (chunkCount === 1) {
        console.log('üì® First chunk received:', text);
      }
    }

    console.log(`‚úÖ Streaming completed: ${chunkCount} chunks, ${totalText.length} characters`);
    console.log('üìÑ Full response:', totalText.substring(0, 200) + '...');

    // Test 4: Streaming with system instruction in message
    console.log('\nüîß Testing streaming with system instruction in message...');
    const systemPrompt = `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡πÉ‡∏ô‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏Ñ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡∏≤‡∏° ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö:
- ‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏£
- ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏™‡∏°‡πÉ‡∏ô‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÄ‡∏Ñ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡∏≤‡∏°
- ‡∏ä‡∏∑‡πà‡∏≠ INCI ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á`;

    const fullPrompt = `${systemPrompt}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∏‡πà‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?`;

    const systemChat = model.startChat({
      history: [],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 500,
      }
    });

    console.log('üîÆ Sending streaming request with system prompt...');
    const systemResult = await systemChat.sendMessageStream(fullPrompt);

    let systemChunkCount = 0;
    let systemTotalText = '';

    for await (const chunk of systemResult.stream) {
      const text = chunk.text();
      systemChunkCount++;
      systemTotalText += text;

      if (systemChunkCount === 1) {
        console.log('üì® First system chunk received:', text);
      }
    }

    console.log(`‚úÖ System streaming completed: ${systemChunkCount} chunks, ${systemTotalText.length} characters`);
    console.log('üìÑ System response:', systemTotalText.substring(0, 200) + '...');

    console.log('\nüéâ All Gemini streaming tests completed!');

  } catch (error) {
    console.error('‚ùå Gemini streaming test failed:', error);
    console.error('Stack:', error.stack);
  }
}

testGeminiStreaming();